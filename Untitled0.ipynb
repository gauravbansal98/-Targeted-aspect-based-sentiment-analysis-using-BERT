{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zBPFB9bu2haM","colab_type":"code","outputId":"646043f6-8ca8-45ea-d593-3aef33851aea","executionInfo":{"status":"ok","timestamp":1590042714363,"user_tz":-330,"elapsed":3150,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZAdNLq5K20GA","colab_type":"code","outputId":"6e45eddb-688c-4203-d3a4-9c55c2482ab3","executionInfo":{"status":"ok","timestamp":1590042715663,"user_tz":-330,"elapsed":4434,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["cd drive/My Drive/ABSA-DistilBERT"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive/ABSA-DistilBERT'\n","/content/drive/My Drive/ABSA-DistilBERT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6eHg6rB23A07","colab_type":"code","outputId":"765e60d0-f4d5-499a-cdbd-c46aa7b1c051","executionInfo":{"status":"ok","timestamp":1590042724623,"user_tz":-330,"elapsed":13382,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":329}},"source":["!pip install transformers"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7s6Q4cvD3dPq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0d04e6e3-938c-4b6e-e70d-a57c629c10f1","executionInfo":{"status":"ok","timestamp":1590051757906,"user_tz":-330,"elapsed":580564,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["!python model.py --num_train_epochs 10 --max_seq_length 512"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-05-21 08:53:01.136156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/21/2020 08:53:03 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/21/2020 08:53:04 - INFO - filelock -   Lock 139816962222568 acquired on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n","05/21/2020 08:53:04 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpsa3ftyjv\n","Downloading: 100% 442/442 [00:00<00:00, 362kB/s]\n","05/21/2020 08:53:04 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json in cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n","05/21/2020 08:53:04 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n","05/21/2020 08:53:04 - INFO - filelock -   Lock 139816962222568 released on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n","05/21/2020 08:53:04 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n","05/21/2020 08:53:04 - INFO - transformers.configuration_utils -   Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","05/21/2020 08:53:04 - INFO - filelock -   Lock 139814192473592 acquired on /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n","05/21/2020 08:53:04 - INFO - transformers.file_utils -   https://cdn.huggingface.co/distilbert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpevgj26s1\n","Downloading: 100% 268M/268M [00:03<00:00, 83.4MB/s]\n","05/21/2020 08:53:07 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/distilbert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n","05/21/2020 08:53:07 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n","05/21/2020 08:53:07 - INFO - filelock -   Lock 139814192473592 released on /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n","05/21/2020 08:53:07 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/distilbert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n","05/21/2020 08:53:09 - INFO - transformers.modeling_utils -   Weights of DistilBertForSequenceClassification not initialized from pretrained model: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n","05/21/2020 08:53:09 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n","05/21/2020 08:53:35 - INFO - __main__ -   Epoch = 1, Batch = 50, Batch loss = 0.808576, Avg loss (per batch) = 0.611133\n","05/21/2020 08:53:56 - INFO - __main__ -   Epoch = 1, Batch = 100, Batch loss = 0.505472, Avg loss (per batch) = 0.554472\n","05/21/2020 08:54:19 - INFO - __main__ -   Epoch = 1, Batch = 150, Batch loss = 0.523024, Avg loss (per batch) = 0.542487\n","05/21/2020 08:54:41 - INFO - __main__ -   Epoch = 1, Batch = 200, Batch loss = 0.292797, Avg loss (per batch) = 0.524072\n","05/21/2020 08:55:03 - INFO - __main__ -   Epoch = 1, Batch = 250, Batch loss = 0.367898, Avg loss (per batch) = 0.500423\n","05/21/2020 08:55:25 - INFO - __main__ -   Epoch = 1, Batch = 300, Batch loss = 0.279104, Avg loss (per batch) = 0.477378\n","05/21/2020 08:55:47 - INFO - __main__ -   Epoch = 1, Batch = 350, Batch loss = 0.381530, Avg loss (per batch) = 0.455389\n","05/21/2020 08:56:09 - INFO - __main__ -   Epoch = 1, Batch = 400, Batch loss = 0.358634, Avg loss (per batch) = 0.439388\n","05/21/2020 08:56:31 - INFO - __main__ -   Epoch = 1, Batch = 450, Batch loss = 0.345540, Avg loss (per batch) = 0.431020\n","05/21/2020 08:56:53 - INFO - __main__ -   Epoch = 1, Batch = 500, Batch loss = 0.567673, Avg loss (per batch) = 0.425022\n","05/21/2020 08:57:15 - INFO - __main__ -   Epoch = 1, Batch = 550, Batch loss = 0.056770, Avg loss (per batch) = 0.414282\n","05/21/2020 08:57:37 - INFO - __main__ -   Epoch = 1, Batch = 600, Batch loss = 0.193872, Avg loss (per batch) = 0.405240\n","05/21/2020 08:57:59 - INFO - __main__ -   Epoch = 1, Batch = 650, Batch loss = 0.801057, Avg loss (per batch) = 0.393065\n","05/21/2020 08:58:21 - INFO - __main__ -   Epoch = 1, Batch = 700, Batch loss = 0.153299, Avg loss (per batch) = 0.383399\n","05/21/2020 08:58:43 - INFO - __main__ -   Epoch = 1, Batch = 750, Batch loss = 0.005159, Avg loss (per batch) = 0.370308\n","05/21/2020 08:59:05 - INFO - __main__ -   Epoch = 1, Batch = 800, Batch loss = 0.552644, Avg loss (per batch) = 0.377104\n","05/21/2020 08:59:27 - INFO - __main__ -   Epoch = 1, Batch = 850, Batch loss = 0.204556, Avg loss (per batch) = 0.374305\n","05/21/2020 08:59:49 - INFO - __main__ -   Epoch = 1, Batch = 900, Batch loss = 0.013821, Avg loss (per batch) = 0.368671\n","05/21/2020 08:59:56 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 09:01:06 - INFO - __main__ -   After 1.000000 epoch, Training loss = 0.362141, Training accuracy = 0.879263\n","05/21/2020 09:01:28 - INFO - __main__ -   Epoch = 2, Batch = 50, Batch loss = 0.140389, Avg loss (per batch) = 0.407569\n","05/21/2020 09:01:50 - INFO - __main__ -   Epoch = 2, Batch = 100, Batch loss = 0.198616, Avg loss (per batch) = 0.297718\n","05/21/2020 09:02:12 - INFO - __main__ -   Epoch = 2, Batch = 150, Batch loss = 0.307297, Avg loss (per batch) = 0.283153\n","05/21/2020 09:02:34 - INFO - __main__ -   Epoch = 2, Batch = 200, Batch loss = 0.229946, Avg loss (per batch) = 0.281320\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O-17rYxwgpOU","colab_type":"code","outputId":"bf8da8b7-66bd-4171-8a71-8d295632af79","executionInfo":{"status":"ok","timestamp":1590062262336,"user_tz":-330,"elapsed":2620546,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python bert_model.py --num_train_epochs 10 --max_seq_length 512 --batch_size 8"],"execution_count":28,"outputs":[{"output_type":"stream","text":["2020-05-21 09:18:11.612830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/21/2020 09:18:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/21/2020 09:18:14 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/21/2020 09:18:14 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","05/21/2020 09:18:14 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/21/2020 09:18:17 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","05/21/2020 09:18:17 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","05/21/2020 09:18:43 - INFO - __main__ -   Epoch = 1, Batch = 50, Batch loss = 0.785451, Avg loss (per batch) = 0.617835\n","05/21/2020 09:19:05 - INFO - __main__ -   Epoch = 1, Batch = 100, Batch loss = 1.365207, Avg loss (per batch) = 0.544998\n","05/21/2020 09:19:28 - INFO - __main__ -   Epoch = 1, Batch = 150, Batch loss = 0.790671, Avg loss (per batch) = 0.507976\n","05/21/2020 09:19:50 - INFO - __main__ -   Epoch = 1, Batch = 200, Batch loss = 0.655292, Avg loss (per batch) = 0.525550\n","05/21/2020 09:20:12 - INFO - __main__ -   Epoch = 1, Batch = 250, Batch loss = 0.408548, Avg loss (per batch) = 0.515401\n","05/21/2020 09:20:35 - INFO - __main__ -   Epoch = 1, Batch = 300, Batch loss = 0.024959, Avg loss (per batch) = 0.518158\n","05/21/2020 09:20:57 - INFO - __main__ -   Epoch = 1, Batch = 350, Batch loss = 0.400297, Avg loss (per batch) = 0.502894\n","05/21/2020 09:21:20 - INFO - __main__ -   Epoch = 1, Batch = 400, Batch loss = 0.520507, Avg loss (per batch) = 0.500418\n","05/21/2020 09:21:42 - INFO - __main__ -   Epoch = 1, Batch = 450, Batch loss = 1.158111, Avg loss (per batch) = 0.489248\n","05/21/2020 09:22:05 - INFO - __main__ -   Epoch = 1, Batch = 500, Batch loss = 0.437152, Avg loss (per batch) = 0.482500\n","05/21/2020 09:22:27 - INFO - __main__ -   Epoch = 1, Batch = 550, Batch loss = 0.678970, Avg loss (per batch) = 0.467932\n","05/21/2020 09:22:49 - INFO - __main__ -   Epoch = 1, Batch = 600, Batch loss = 0.040727, Avg loss (per batch) = 0.459189\n","05/21/2020 09:23:12 - INFO - __main__ -   Epoch = 1, Batch = 650, Batch loss = 0.063201, Avg loss (per batch) = 0.453147\n","05/21/2020 09:23:34 - INFO - __main__ -   Epoch = 1, Batch = 700, Batch loss = 0.355577, Avg loss (per batch) = 0.441772\n","05/21/2020 09:23:57 - INFO - __main__ -   Epoch = 1, Batch = 750, Batch loss = 0.006623, Avg loss (per batch) = 0.435271\n","05/21/2020 09:24:19 - INFO - __main__ -   Epoch = 1, Batch = 800, Batch loss = 0.464231, Avg loss (per batch) = 0.434127\n","05/21/2020 09:24:42 - INFO - __main__ -   Epoch = 1, Batch = 850, Batch loss = 0.520619, Avg loss (per batch) = 0.427816\n","05/21/2020 09:25:04 - INFO - __main__ -   Epoch = 1, Batch = 900, Batch loss = 0.388276, Avg loss (per batch) = 0.426865\n","05/21/2020 09:25:27 - INFO - __main__ -   Epoch = 1, Batch = 950, Batch loss = 0.155212, Avg loss (per batch) = 0.426741\n","05/21/2020 09:25:49 - INFO - __main__ -   Epoch = 1, Batch = 1000, Batch loss = 0.045244, Avg loss (per batch) = 0.423736\n","05/21/2020 09:26:11 - INFO - __main__ -   Epoch = 1, Batch = 1050, Batch loss = 0.340707, Avg loss (per batch) = 0.423216\n","05/21/2020 09:26:34 - INFO - __main__ -   Epoch = 1, Batch = 1100, Batch loss = 0.026226, Avg loss (per batch) = 0.418537\n","05/21/2020 09:26:56 - INFO - __main__ -   Epoch = 1, Batch = 1150, Batch loss = 0.006046, Avg loss (per batch) = 0.411214\n","05/21/2020 09:27:19 - INFO - __main__ -   Epoch = 1, Batch = 1200, Batch loss = 0.424087, Avg loss (per batch) = 0.408427\n","05/21/2020 09:27:41 - INFO - __main__ -   Epoch = 1, Batch = 1250, Batch loss = 0.595268, Avg loss (per batch) = 0.400927\n","05/21/2020 09:28:04 - INFO - __main__ -   Epoch = 1, Batch = 1300, Batch loss = 0.986596, Avg loss (per batch) = 0.398209\n","05/21/2020 09:28:26 - INFO - __main__ -   Epoch = 1, Batch = 1350, Batch loss = 0.113778, Avg loss (per batch) = 0.393077\n","05/21/2020 09:28:49 - INFO - __main__ -   Epoch = 1, Batch = 1400, Batch loss = 0.004410, Avg loss (per batch) = 0.388438\n","05/21/2020 09:29:11 - INFO - __main__ -   Epoch = 1, Batch = 1450, Batch loss = 0.006821, Avg loss (per batch) = 0.382454\n","05/21/2020 09:29:33 - INFO - __main__ -   Epoch = 1, Batch = 1500, Batch loss = 0.000933, Avg loss (per batch) = 0.375220\n","05/21/2020 09:29:56 - INFO - __main__ -   Epoch = 1, Batch = 1550, Batch loss = 0.000658, Avg loss (per batch) = 0.363146\n","05/21/2020 09:30:18 - INFO - __main__ -   Epoch = 1, Batch = 1600, Batch loss = 0.145192, Avg loss (per batch) = 0.369160\n","05/21/2020 09:30:41 - INFO - __main__ -   Epoch = 1, Batch = 1650, Batch loss = 0.202932, Avg loss (per batch) = 0.366575\n","05/21/2020 09:31:03 - INFO - __main__ -   Epoch = 1, Batch = 1700, Batch loss = 0.005023, Avg loss (per batch) = 0.365820\n","05/21/2020 09:31:25 - INFO - __main__ -   Epoch = 1, Batch = 1750, Batch loss = 0.016094, Avg loss (per batch) = 0.364319\n","05/21/2020 09:31:48 - INFO - __main__ -   Epoch = 1, Batch = 1800, Batch loss = 0.001696, Avg loss (per batch) = 0.360902\n","05/21/2020 09:32:02 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 09:34:18 - INFO - __main__ -   After 1.000000 epoch, Training loss = 0.354444, Training accuracy = 0.883492\n","05/21/2020 09:34:40 - INFO - __main__ -   Epoch = 2, Batch = 50, Batch loss = 0.381531, Avg loss (per batch) = 0.525550\n","05/21/2020 09:35:03 - INFO - __main__ -   Epoch = 2, Batch = 100, Batch loss = 0.084347, Avg loss (per batch) = 0.344993\n","05/21/2020 09:35:25 - INFO - __main__ -   Epoch = 2, Batch = 150, Batch loss = 0.546175, Avg loss (per batch) = 0.293217\n","05/21/2020 09:35:47 - INFO - __main__ -   Epoch = 2, Batch = 200, Batch loss = 0.560610, Avg loss (per batch) = 0.282290\n","05/21/2020 09:36:10 - INFO - __main__ -   Epoch = 2, Batch = 250, Batch loss = 0.145933, Avg loss (per batch) = 0.291517\n","05/21/2020 09:36:32 - INFO - __main__ -   Epoch = 2, Batch = 300, Batch loss = 0.000864, Avg loss (per batch) = 0.280276\n","05/21/2020 09:36:55 - INFO - __main__ -   Epoch = 2, Batch = 350, Batch loss = 0.408280, Avg loss (per batch) = 0.281420\n","05/21/2020 09:37:17 - INFO - __main__ -   Epoch = 2, Batch = 400, Batch loss = 0.108862, Avg loss (per batch) = 0.273853\n","05/21/2020 09:37:39 - INFO - __main__ -   Epoch = 2, Batch = 450, Batch loss = 0.558332, Avg loss (per batch) = 0.260397\n","05/21/2020 09:38:02 - INFO - __main__ -   Epoch = 2, Batch = 500, Batch loss = 0.020391, Avg loss (per batch) = 0.256563\n","05/21/2020 09:38:24 - INFO - __main__ -   Epoch = 2, Batch = 550, Batch loss = 0.630366, Avg loss (per batch) = 0.251156\n","05/21/2020 09:38:47 - INFO - __main__ -   Epoch = 2, Batch = 600, Batch loss = 0.421976, Avg loss (per batch) = 0.249146\n","05/21/2020 09:39:09 - INFO - __main__ -   Epoch = 2, Batch = 650, Batch loss = 0.006548, Avg loss (per batch) = 0.244645\n","05/21/2020 09:39:31 - INFO - __main__ -   Epoch = 2, Batch = 700, Batch loss = 0.005396, Avg loss (per batch) = 0.240124\n","05/21/2020 09:39:54 - INFO - __main__ -   Epoch = 2, Batch = 750, Batch loss = 0.000833, Avg loss (per batch) = 0.235616\n","05/21/2020 09:40:16 - INFO - __main__ -   Epoch = 2, Batch = 800, Batch loss = 0.642883, Avg loss (per batch) = 0.234965\n","05/21/2020 09:40:39 - INFO - __main__ -   Epoch = 2, Batch = 850, Batch loss = 0.057731, Avg loss (per batch) = 0.232324\n","05/21/2020 09:41:01 - INFO - __main__ -   Epoch = 2, Batch = 900, Batch loss = 0.006597, Avg loss (per batch) = 0.235324\n","05/21/2020 09:41:23 - INFO - __main__ -   Epoch = 2, Batch = 950, Batch loss = 0.003608, Avg loss (per batch) = 0.239366\n","05/21/2020 09:41:46 - INFO - __main__ -   Epoch = 2, Batch = 1000, Batch loss = 0.007309, Avg loss (per batch) = 0.237241\n","05/21/2020 09:42:08 - INFO - __main__ -   Epoch = 2, Batch = 1050, Batch loss = 0.089040, Avg loss (per batch) = 0.237054\n","05/21/2020 09:42:30 - INFO - __main__ -   Epoch = 2, Batch = 1100, Batch loss = 0.002025, Avg loss (per batch) = 0.234209\n","05/21/2020 09:42:53 - INFO - __main__ -   Epoch = 2, Batch = 1150, Batch loss = 0.000441, Avg loss (per batch) = 0.232745\n","05/21/2020 09:43:15 - INFO - __main__ -   Epoch = 2, Batch = 1200, Batch loss = 0.214250, Avg loss (per batch) = 0.228802\n","05/21/2020 09:43:38 - INFO - __main__ -   Epoch = 2, Batch = 1250, Batch loss = 0.186081, Avg loss (per batch) = 0.224864\n","05/21/2020 09:44:00 - INFO - __main__ -   Epoch = 2, Batch = 1300, Batch loss = 0.247553, Avg loss (per batch) = 0.224509\n","05/21/2020 09:44:22 - INFO - __main__ -   Epoch = 2, Batch = 1350, Batch loss = 0.001388, Avg loss (per batch) = 0.222579\n","05/21/2020 09:44:45 - INFO - __main__ -   Epoch = 2, Batch = 1400, Batch loss = 0.000426, Avg loss (per batch) = 0.220300\n","05/21/2020 09:45:07 - INFO - __main__ -   Epoch = 2, Batch = 1450, Batch loss = 0.001251, Avg loss (per batch) = 0.218867\n","05/21/2020 09:45:29 - INFO - __main__ -   Epoch = 2, Batch = 1500, Batch loss = 0.000387, Avg loss (per batch) = 0.216490\n","05/21/2020 09:45:52 - INFO - __main__ -   Epoch = 2, Batch = 1550, Batch loss = 0.000252, Avg loss (per batch) = 0.209523\n","05/21/2020 09:46:14 - INFO - __main__ -   Epoch = 2, Batch = 1600, Batch loss = 0.009476, Avg loss (per batch) = 0.215738\n","05/21/2020 09:46:37 - INFO - __main__ -   Epoch = 2, Batch = 1650, Batch loss = 0.509488, Avg loss (per batch) = 0.215684\n","05/21/2020 09:46:59 - INFO - __main__ -   Epoch = 2, Batch = 1700, Batch loss = 0.000905, Avg loss (per batch) = 0.215241\n","05/21/2020 09:47:21 - INFO - __main__ -   Epoch = 2, Batch = 1750, Batch loss = 0.005906, Avg loss (per batch) = 0.215649\n","05/21/2020 09:47:44 - INFO - __main__ -   Epoch = 2, Batch = 1800, Batch loss = 0.000356, Avg loss (per batch) = 0.213863\n","05/21/2020 09:47:58 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 09:50:13 - INFO - __main__ -   After 2.000000 epoch, Training loss = 0.210284, Training accuracy = 0.941269\n","05/21/2020 09:50:36 - INFO - __main__ -   Epoch = 3, Batch = 50, Batch loss = 0.452829, Avg loss (per batch) = 0.372671\n","05/21/2020 09:50:58 - INFO - __main__ -   Epoch = 3, Batch = 100, Batch loss = 0.028817, Avg loss (per batch) = 0.241218\n","05/21/2020 09:51:20 - INFO - __main__ -   Epoch = 3, Batch = 150, Batch loss = 0.047953, Avg loss (per batch) = 0.182361\n","05/21/2020 09:51:43 - INFO - __main__ -   Epoch = 3, Batch = 200, Batch loss = 0.097553, Avg loss (per batch) = 0.171020\n","05/21/2020 09:52:05 - INFO - __main__ -   Epoch = 3, Batch = 250, Batch loss = 0.005287, Avg loss (per batch) = 0.177709\n","05/21/2020 09:52:28 - INFO - __main__ -   Epoch = 3, Batch = 300, Batch loss = 0.000375, Avg loss (per batch) = 0.182624\n","05/21/2020 09:52:50 - INFO - __main__ -   Epoch = 3, Batch = 350, Batch loss = 0.002846, Avg loss (per batch) = 0.182860\n","05/21/2020 09:53:12 - INFO - __main__ -   Epoch = 3, Batch = 400, Batch loss = 0.354629, Avg loss (per batch) = 0.181551\n","05/21/2020 09:53:35 - INFO - __main__ -   Epoch = 3, Batch = 450, Batch loss = 1.368388, Avg loss (per batch) = 0.173627\n","05/21/2020 09:53:57 - INFO - __main__ -   Epoch = 3, Batch = 500, Batch loss = 0.061125, Avg loss (per batch) = 0.176646\n","05/21/2020 09:54:19 - INFO - __main__ -   Epoch = 3, Batch = 550, Batch loss = 0.478990, Avg loss (per batch) = 0.168937\n","05/21/2020 09:54:42 - INFO - __main__ -   Epoch = 3, Batch = 600, Batch loss = 0.531184, Avg loss (per batch) = 0.167282\n","05/21/2020 09:55:04 - INFO - __main__ -   Epoch = 3, Batch = 650, Batch loss = 0.001104, Avg loss (per batch) = 0.165470\n","05/21/2020 09:55:26 - INFO - __main__ -   Epoch = 3, Batch = 700, Batch loss = 0.001421, Avg loss (per batch) = 0.159636\n","05/21/2020 09:55:49 - INFO - __main__ -   Epoch = 3, Batch = 750, Batch loss = 0.000385, Avg loss (per batch) = 0.157062\n","05/21/2020 09:56:11 - INFO - __main__ -   Epoch = 3, Batch = 800, Batch loss = 0.738543, Avg loss (per batch) = 0.159062\n","05/21/2020 09:56:33 - INFO - __main__ -   Epoch = 3, Batch = 850, Batch loss = 0.181391, Avg loss (per batch) = 0.157763\n","05/21/2020 09:56:56 - INFO - __main__ -   Epoch = 3, Batch = 900, Batch loss = 0.003335, Avg loss (per batch) = 0.157170\n","05/21/2020 09:57:18 - INFO - __main__ -   Epoch = 3, Batch = 950, Batch loss = 0.001113, Avg loss (per batch) = 0.160854\n","05/21/2020 09:57:40 - INFO - __main__ -   Epoch = 3, Batch = 1000, Batch loss = 0.000495, Avg loss (per batch) = 0.161174\n","05/21/2020 09:58:03 - INFO - __main__ -   Epoch = 3, Batch = 1050, Batch loss = 0.026276, Avg loss (per batch) = 0.162127\n","05/21/2020 09:58:25 - INFO - __main__ -   Epoch = 3, Batch = 1100, Batch loss = 0.001268, Avg loss (per batch) = 0.158181\n","05/21/2020 09:58:48 - INFO - __main__ -   Epoch = 3, Batch = 1150, Batch loss = 0.008943, Avg loss (per batch) = 0.158560\n","05/21/2020 09:59:10 - INFO - __main__ -   Epoch = 3, Batch = 1200, Batch loss = 0.006052, Avg loss (per batch) = 0.156161\n","05/21/2020 09:59:32 - INFO - __main__ -   Epoch = 3, Batch = 1250, Batch loss = 0.017579, Avg loss (per batch) = 0.152520\n","05/21/2020 09:59:55 - INFO - __main__ -   Epoch = 3, Batch = 1300, Batch loss = 0.004335, Avg loss (per batch) = 0.151010\n","05/21/2020 10:00:17 - INFO - __main__ -   Epoch = 3, Batch = 1350, Batch loss = 0.000831, Avg loss (per batch) = 0.148664\n","05/21/2020 10:00:39 - INFO - __main__ -   Epoch = 3, Batch = 1400, Batch loss = 0.000128, Avg loss (per batch) = 0.147727\n","05/21/2020 10:01:02 - INFO - __main__ -   Epoch = 3, Batch = 1450, Batch loss = 0.000548, Avg loss (per batch) = 0.147486\n","05/21/2020 10:01:24 - INFO - __main__ -   Epoch = 3, Batch = 1500, Batch loss = 0.000147, Avg loss (per batch) = 0.146491\n","05/21/2020 10:01:47 - INFO - __main__ -   Epoch = 3, Batch = 1550, Batch loss = 0.000129, Avg loss (per batch) = 0.142381\n","05/21/2020 10:02:09 - INFO - __main__ -   Epoch = 3, Batch = 1600, Batch loss = 0.004416, Avg loss (per batch) = 0.146737\n","05/21/2020 10:02:31 - INFO - __main__ -   Epoch = 3, Batch = 1650, Batch loss = 0.656511, Avg loss (per batch) = 0.146229\n","05/21/2020 10:02:54 - INFO - __main__ -   Epoch = 3, Batch = 1700, Batch loss = 0.000627, Avg loss (per batch) = 0.146571\n","05/21/2020 10:03:16 - INFO - __main__ -   Epoch = 3, Batch = 1750, Batch loss = 0.004273, Avg loss (per batch) = 0.147652\n","05/21/2020 10:03:38 - INFO - __main__ -   Epoch = 3, Batch = 1800, Batch loss = 0.000162, Avg loss (per batch) = 0.145829\n","05/21/2020 10:03:53 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 10:06:08 - INFO - __main__ -   After 3.000000 epoch, Training loss = 0.143746, Training accuracy = 0.964052\n","05/21/2020 10:06:31 - INFO - __main__ -   Epoch = 4, Batch = 50, Batch loss = 0.028534, Avg loss (per batch) = 0.210295\n","05/21/2020 10:06:53 - INFO - __main__ -   Epoch = 4, Batch = 100, Batch loss = 0.017216, Avg loss (per batch) = 0.132741\n","05/21/2020 10:07:15 - INFO - __main__ -   Epoch = 4, Batch = 150, Batch loss = 0.001675, Avg loss (per batch) = 0.093816\n","05/21/2020 10:07:38 - INFO - __main__ -   Epoch = 4, Batch = 200, Batch loss = 0.024852, Avg loss (per batch) = 0.107669\n","05/21/2020 10:08:00 - INFO - __main__ -   Epoch = 4, Batch = 250, Batch loss = 0.001391, Avg loss (per batch) = 0.116002\n","05/21/2020 10:08:22 - INFO - __main__ -   Epoch = 4, Batch = 300, Batch loss = 0.000124, Avg loss (per batch) = 0.106447\n","05/21/2020 10:08:45 - INFO - __main__ -   Epoch = 4, Batch = 350, Batch loss = 0.000888, Avg loss (per batch) = 0.105973\n","05/21/2020 10:09:07 - INFO - __main__ -   Epoch = 4, Batch = 400, Batch loss = 0.106509, Avg loss (per batch) = 0.112318\n","05/21/2020 10:09:29 - INFO - __main__ -   Epoch = 4, Batch = 450, Batch loss = 1.236997, Avg loss (per batch) = 0.108353\n","05/21/2020 10:09:52 - INFO - __main__ -   Epoch = 4, Batch = 500, Batch loss = 0.008090, Avg loss (per batch) = 0.105644\n","05/21/2020 10:10:14 - INFO - __main__ -   Epoch = 4, Batch = 550, Batch loss = 0.011142, Avg loss (per batch) = 0.102583\n","05/21/2020 10:10:36 - INFO - __main__ -   Epoch = 4, Batch = 600, Batch loss = 0.000283, Avg loss (per batch) = 0.097769\n","05/21/2020 10:10:59 - INFO - __main__ -   Epoch = 4, Batch = 650, Batch loss = 0.000281, Avg loss (per batch) = 0.099157\n","05/21/2020 10:11:21 - INFO - __main__ -   Epoch = 4, Batch = 700, Batch loss = 0.000647, Avg loss (per batch) = 0.097510\n","05/21/2020 10:11:44 - INFO - __main__ -   Epoch = 4, Batch = 750, Batch loss = 0.000093, Avg loss (per batch) = 0.093431\n","05/21/2020 10:12:06 - INFO - __main__ -   Epoch = 4, Batch = 800, Batch loss = 0.347611, Avg loss (per batch) = 0.092967\n","05/21/2020 10:12:28 - INFO - __main__ -   Epoch = 4, Batch = 850, Batch loss = 0.001069, Avg loss (per batch) = 0.091062\n","05/21/2020 10:12:51 - INFO - __main__ -   Epoch = 4, Batch = 900, Batch loss = 0.001118, Avg loss (per batch) = 0.096453\n","05/21/2020 10:13:13 - INFO - __main__ -   Epoch = 4, Batch = 950, Batch loss = 0.000476, Avg loss (per batch) = 0.100557\n","05/21/2020 10:13:35 - INFO - __main__ -   Epoch = 4, Batch = 1000, Batch loss = 0.000252, Avg loss (per batch) = 0.102471\n","05/21/2020 10:13:58 - INFO - __main__ -   Epoch = 4, Batch = 1050, Batch loss = 0.019083, Avg loss (per batch) = 0.101538\n","05/21/2020 10:14:20 - INFO - __main__ -   Epoch = 4, Batch = 1100, Batch loss = 0.000790, Avg loss (per batch) = 0.099751\n","05/21/2020 10:14:42 - INFO - __main__ -   Epoch = 4, Batch = 1150, Batch loss = 0.000087, Avg loss (per batch) = 0.103148\n","05/21/2020 10:15:05 - INFO - __main__ -   Epoch = 4, Batch = 1200, Batch loss = 0.000863, Avg loss (per batch) = 0.100969\n","05/21/2020 10:15:27 - INFO - __main__ -   Epoch = 4, Batch = 1250, Batch loss = 0.001919, Avg loss (per batch) = 0.098789\n","05/21/2020 10:15:49 - INFO - __main__ -   Epoch = 4, Batch = 1300, Batch loss = 0.002563, Avg loss (per batch) = 0.097276\n","05/21/2020 10:16:12 - INFO - __main__ -   Epoch = 4, Batch = 1350, Batch loss = 0.000776, Avg loss (per batch) = 0.096102\n","05/21/2020 10:16:34 - INFO - __main__ -   Epoch = 4, Batch = 1400, Batch loss = 0.000135, Avg loss (per batch) = 0.096219\n","05/21/2020 10:16:57 - INFO - __main__ -   Epoch = 4, Batch = 1450, Batch loss = 0.000474, Avg loss (per batch) = 0.097422\n","05/21/2020 10:17:19 - INFO - __main__ -   Epoch = 4, Batch = 1500, Batch loss = 0.000078, Avg loss (per batch) = 0.095669\n","05/21/2020 10:17:41 - INFO - __main__ -   Epoch = 4, Batch = 1550, Batch loss = 0.000106, Avg loss (per batch) = 0.093339\n","05/21/2020 10:18:04 - INFO - __main__ -   Epoch = 4, Batch = 1600, Batch loss = 0.016965, Avg loss (per batch) = 0.097717\n","05/21/2020 10:18:26 - INFO - __main__ -   Epoch = 4, Batch = 1650, Batch loss = 0.430184, Avg loss (per batch) = 0.097621\n","05/21/2020 10:18:48 - INFO - __main__ -   Epoch = 4, Batch = 1700, Batch loss = 0.000125, Avg loss (per batch) = 0.097459\n","05/21/2020 10:19:11 - INFO - __main__ -   Epoch = 4, Batch = 1750, Batch loss = 0.000757, Avg loss (per batch) = 0.098587\n","05/21/2020 10:19:33 - INFO - __main__ -   Epoch = 4, Batch = 1800, Batch loss = 0.000061, Avg loss (per batch) = 0.096938\n","05/21/2020 10:19:48 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 10:22:03 - INFO - __main__ -   After 4.000000 epoch, Training loss = 0.096070, Training accuracy = 0.975989\n","05/21/2020 10:22:26 - INFO - __main__ -   Epoch = 5, Batch = 50, Batch loss = 0.004266, Avg loss (per batch) = 0.140911\n","05/21/2020 10:22:48 - INFO - __main__ -   Epoch = 5, Batch = 100, Batch loss = 0.001404, Avg loss (per batch) = 0.084031\n","05/21/2020 10:23:10 - INFO - __main__ -   Epoch = 5, Batch = 150, Batch loss = 0.000434, Avg loss (per batch) = 0.061289\n","05/21/2020 10:23:33 - INFO - __main__ -   Epoch = 5, Batch = 200, Batch loss = 0.032305, Avg loss (per batch) = 0.063314\n","05/21/2020 10:23:55 - INFO - __main__ -   Epoch = 5, Batch = 250, Batch loss = 0.001580, Avg loss (per batch) = 0.062332\n","05/21/2020 10:24:17 - INFO - __main__ -   Epoch = 5, Batch = 300, Batch loss = 0.000055, Avg loss (per batch) = 0.067976\n","05/21/2020 10:24:40 - INFO - __main__ -   Epoch = 5, Batch = 350, Batch loss = 0.002711, Avg loss (per batch) = 0.070476\n","05/21/2020 10:25:02 - INFO - __main__ -   Epoch = 5, Batch = 400, Batch loss = 0.002292, Avg loss (per batch) = 0.071586\n","05/21/2020 10:25:25 - INFO - __main__ -   Epoch = 5, Batch = 450, Batch loss = 0.135115, Avg loss (per batch) = 0.066081\n","05/21/2020 10:25:47 - INFO - __main__ -   Epoch = 5, Batch = 500, Batch loss = 0.006069, Avg loss (per batch) = 0.068099\n","05/21/2020 10:26:09 - INFO - __main__ -   Epoch = 5, Batch = 550, Batch loss = 0.119413, Avg loss (per batch) = 0.067960\n","05/21/2020 10:26:32 - INFO - __main__ -   Epoch = 5, Batch = 600, Batch loss = 0.000104, Avg loss (per batch) = 0.065198\n","05/21/2020 10:26:54 - INFO - __main__ -   Epoch = 5, Batch = 650, Batch loss = 0.000169, Avg loss (per batch) = 0.065169\n","05/21/2020 10:27:17 - INFO - __main__ -   Epoch = 5, Batch = 700, Batch loss = 0.000382, Avg loss (per batch) = 0.060777\n","05/21/2020 10:27:39 - INFO - __main__ -   Epoch = 5, Batch = 750, Batch loss = 0.000058, Avg loss (per batch) = 0.058385\n","05/21/2020 10:28:01 - INFO - __main__ -   Epoch = 5, Batch = 800, Batch loss = 0.291197, Avg loss (per batch) = 0.059998\n","05/21/2020 10:28:24 - INFO - __main__ -   Epoch = 5, Batch = 850, Batch loss = 0.000651, Avg loss (per batch) = 0.059864\n","05/21/2020 10:28:46 - INFO - __main__ -   Epoch = 5, Batch = 900, Batch loss = 0.000791, Avg loss (per batch) = 0.061946\n","05/21/2020 10:29:08 - INFO - __main__ -   Epoch = 5, Batch = 950, Batch loss = 0.000327, Avg loss (per batch) = 0.065038\n","05/21/2020 10:29:31 - INFO - __main__ -   Epoch = 5, Batch = 1000, Batch loss = 0.000170, Avg loss (per batch) = 0.066831\n","05/21/2020 10:29:53 - INFO - __main__ -   Epoch = 5, Batch = 1050, Batch loss = 0.003808, Avg loss (per batch) = 0.066395\n","05/21/2020 10:30:16 - INFO - __main__ -   Epoch = 5, Batch = 1100, Batch loss = 0.000570, Avg loss (per batch) = 0.066637\n","05/21/2020 10:30:38 - INFO - __main__ -   Epoch = 5, Batch = 1150, Batch loss = 0.000144, Avg loss (per batch) = 0.067151\n","05/21/2020 10:31:00 - INFO - __main__ -   Epoch = 5, Batch = 1200, Batch loss = 0.000466, Avg loss (per batch) = 0.065678\n","05/21/2020 10:31:23 - INFO - __main__ -   Epoch = 5, Batch = 1250, Batch loss = 0.000458, Avg loss (per batch) = 0.065548\n","05/21/2020 10:31:45 - INFO - __main__ -   Epoch = 5, Batch = 1300, Batch loss = 0.000834, Avg loss (per batch) = 0.064255\n","05/21/2020 10:32:07 - INFO - __main__ -   Epoch = 5, Batch = 1350, Batch loss = 0.000222, Avg loss (per batch) = 0.063671\n","05/21/2020 10:32:30 - INFO - __main__ -   Epoch = 5, Batch = 1400, Batch loss = 0.000087, Avg loss (per batch) = 0.063325\n","05/21/2020 10:32:52 - INFO - __main__ -   Epoch = 5, Batch = 1450, Batch loss = 0.000365, Avg loss (per batch) = 0.064122\n","05/21/2020 10:33:15 - INFO - __main__ -   Epoch = 5, Batch = 1500, Batch loss = 0.000103, Avg loss (per batch) = 0.063206\n","05/21/2020 10:33:37 - INFO - __main__ -   Epoch = 5, Batch = 1550, Batch loss = 0.000079, Avg loss (per batch) = 0.062017\n","05/21/2020 10:33:59 - INFO - __main__ -   Epoch = 5, Batch = 1600, Batch loss = 0.000373, Avg loss (per batch) = 0.066194\n","05/21/2020 10:34:22 - INFO - __main__ -   Epoch = 5, Batch = 1650, Batch loss = 0.002082, Avg loss (per batch) = 0.065166\n","05/21/2020 10:34:44 - INFO - __main__ -   Epoch = 5, Batch = 1700, Batch loss = 0.000129, Avg loss (per batch) = 0.066493\n","05/21/2020 10:35:06 - INFO - __main__ -   Epoch = 5, Batch = 1750, Batch loss = 0.000370, Avg loss (per batch) = 0.067888\n","05/21/2020 10:35:29 - INFO - __main__ -   Epoch = 5, Batch = 1800, Batch loss = 0.000064, Avg loss (per batch) = 0.067006\n","05/21/2020 10:35:43 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 10:37:59 - INFO - __main__ -   After 5.000000 epoch, Training loss = 0.066725, Training accuracy = 0.983970\n","05/21/2020 10:38:21 - INFO - __main__ -   Epoch = 6, Batch = 50, Batch loss = 0.002630, Avg loss (per batch) = 0.076926\n","05/21/2020 10:38:43 - INFO - __main__ -   Epoch = 6, Batch = 100, Batch loss = 0.000970, Avg loss (per batch) = 0.040263\n","05/21/2020 10:39:06 - INFO - __main__ -   Epoch = 6, Batch = 150, Batch loss = 0.000340, Avg loss (per batch) = 0.029052\n","05/21/2020 10:39:28 - INFO - __main__ -   Epoch = 6, Batch = 200, Batch loss = 0.001277, Avg loss (per batch) = 0.047142\n","05/21/2020 10:39:50 - INFO - __main__ -   Epoch = 6, Batch = 250, Batch loss = 0.000273, Avg loss (per batch) = 0.052036\n","05/21/2020 10:40:13 - INFO - __main__ -   Epoch = 6, Batch = 300, Batch loss = 0.000063, Avg loss (per batch) = 0.056704\n","05/21/2020 10:40:35 - INFO - __main__ -   Epoch = 6, Batch = 350, Batch loss = 0.000275, Avg loss (per batch) = 0.055760\n","05/21/2020 10:40:57 - INFO - __main__ -   Epoch = 6, Batch = 400, Batch loss = 0.000819, Avg loss (per batch) = 0.057048\n","05/21/2020 10:41:20 - INFO - __main__ -   Epoch = 6, Batch = 450, Batch loss = 0.383859, Avg loss (per batch) = 0.056702\n","05/21/2020 10:41:42 - INFO - __main__ -   Epoch = 6, Batch = 500, Batch loss = 0.048518, Avg loss (per batch) = 0.053673\n","05/21/2020 10:42:05 - INFO - __main__ -   Epoch = 6, Batch = 550, Batch loss = 0.000830, Avg loss (per batch) = 0.050941\n","05/21/2020 10:42:27 - INFO - __main__ -   Epoch = 6, Batch = 600, Batch loss = 0.000083, Avg loss (per batch) = 0.050472\n","05/21/2020 10:42:49 - INFO - __main__ -   Epoch = 6, Batch = 650, Batch loss = 0.000078, Avg loss (per batch) = 0.050495\n","05/21/2020 10:43:12 - INFO - __main__ -   Epoch = 6, Batch = 700, Batch loss = 0.000186, Avg loss (per batch) = 0.050789\n","05/21/2020 10:43:34 - INFO - __main__ -   Epoch = 6, Batch = 750, Batch loss = 0.000112, Avg loss (per batch) = 0.047884\n","05/21/2020 10:43:56 - INFO - __main__ -   Epoch = 6, Batch = 800, Batch loss = 0.115959, Avg loss (per batch) = 0.048347\n","05/21/2020 10:44:19 - INFO - __main__ -   Epoch = 6, Batch = 850, Batch loss = 0.001282, Avg loss (per batch) = 0.049316\n","05/21/2020 10:44:41 - INFO - __main__ -   Epoch = 6, Batch = 900, Batch loss = 0.000187, Avg loss (per batch) = 0.049472\n","05/21/2020 10:45:04 - INFO - __main__ -   Epoch = 6, Batch = 950, Batch loss = 0.000150, Avg loss (per batch) = 0.051255\n","05/21/2020 10:45:26 - INFO - __main__ -   Epoch = 6, Batch = 1000, Batch loss = 0.000063, Avg loss (per batch) = 0.052859\n","05/21/2020 10:45:48 - INFO - __main__ -   Epoch = 6, Batch = 1050, Batch loss = 0.001176, Avg loss (per batch) = 0.054178\n","05/21/2020 10:46:11 - INFO - __main__ -   Epoch = 6, Batch = 1100, Batch loss = 0.000262, Avg loss (per batch) = 0.052389\n","05/21/2020 10:46:33 - INFO - __main__ -   Epoch = 6, Batch = 1150, Batch loss = 0.000046, Avg loss (per batch) = 0.052694\n","05/21/2020 10:46:55 - INFO - __main__ -   Epoch = 6, Batch = 1200, Batch loss = 0.000191, Avg loss (per batch) = 0.051211\n","05/21/2020 10:47:18 - INFO - __main__ -   Epoch = 6, Batch = 1250, Batch loss = 0.001145, Avg loss (per batch) = 0.050823\n","05/21/2020 10:47:40 - INFO - __main__ -   Epoch = 6, Batch = 1300, Batch loss = 0.000625, Avg loss (per batch) = 0.049773\n","05/21/2020 10:48:02 - INFO - __main__ -   Epoch = 6, Batch = 1350, Batch loss = 0.000105, Avg loss (per batch) = 0.048566\n","05/21/2020 10:48:25 - INFO - __main__ -   Epoch = 6, Batch = 1400, Batch loss = 0.000036, Avg loss (per batch) = 0.047964\n","05/21/2020 10:48:47 - INFO - __main__ -   Epoch = 6, Batch = 1450, Batch loss = 0.000066, Avg loss (per batch) = 0.047678\n","05/21/2020 10:49:10 - INFO - __main__ -   Epoch = 6, Batch = 1500, Batch loss = 0.000029, Avg loss (per batch) = 0.047465\n","05/21/2020 10:49:32 - INFO - __main__ -   Epoch = 6, Batch = 1550, Batch loss = 0.000033, Avg loss (per batch) = 0.047133\n","05/21/2020 10:49:54 - INFO - __main__ -   Epoch = 6, Batch = 1600, Batch loss = 0.000100, Avg loss (per batch) = 0.051538\n","05/21/2020 10:50:17 - INFO - __main__ -   Epoch = 6, Batch = 1650, Batch loss = 0.000259, Avg loss (per batch) = 0.051294\n","05/21/2020 10:50:39 - INFO - __main__ -   Epoch = 6, Batch = 1700, Batch loss = 0.000085, Avg loss (per batch) = 0.051697\n","05/21/2020 10:51:01 - INFO - __main__ -   Epoch = 6, Batch = 1750, Batch loss = 0.000218, Avg loss (per batch) = 0.051120\n","05/21/2020 10:51:24 - INFO - __main__ -   Epoch = 6, Batch = 1800, Batch loss = 0.000033, Avg loss (per batch) = 0.049836\n","05/21/2020 10:51:38 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 10:53:53 - INFO - __main__ -   After 6.000000 epoch, Training loss = 0.050169, Training accuracy = 0.987926\n","05/21/2020 10:54:16 - INFO - __main__ -   Epoch = 7, Batch = 50, Batch loss = 0.000247, Avg loss (per batch) = 0.017114\n","05/21/2020 10:54:38 - INFO - __main__ -   Epoch = 7, Batch = 100, Batch loss = 0.000446, Avg loss (per batch) = 0.013677\n","05/21/2020 10:55:00 - INFO - __main__ -   Epoch = 7, Batch = 150, Batch loss = 0.000107, Avg loss (per batch) = 0.009316\n","05/21/2020 10:55:23 - INFO - __main__ -   Epoch = 7, Batch = 200, Batch loss = 0.000291, Avg loss (per batch) = 0.021713\n","05/21/2020 10:55:45 - INFO - __main__ -   Epoch = 7, Batch = 250, Batch loss = 0.000123, Avg loss (per batch) = 0.021281\n","05/21/2020 10:56:08 - INFO - __main__ -   Epoch = 7, Batch = 300, Batch loss = 0.000039, Avg loss (per batch) = 0.020675\n","05/21/2020 10:56:30 - INFO - __main__ -   Epoch = 7, Batch = 350, Batch loss = 0.000106, Avg loss (per batch) = 0.021875\n","05/21/2020 10:56:52 - INFO - __main__ -   Epoch = 7, Batch = 400, Batch loss = 0.000311, Avg loss (per batch) = 0.023318\n","05/21/2020 10:57:15 - INFO - __main__ -   Epoch = 7, Batch = 450, Batch loss = 0.000287, Avg loss (per batch) = 0.024953\n","05/21/2020 10:57:37 - INFO - __main__ -   Epoch = 7, Batch = 500, Batch loss = 0.000488, Avg loss (per batch) = 0.027196\n","05/21/2020 10:57:59 - INFO - __main__ -   Epoch = 7, Batch = 550, Batch loss = 0.000437, Avg loss (per batch) = 0.026997\n","05/21/2020 10:58:22 - INFO - __main__ -   Epoch = 7, Batch = 600, Batch loss = 0.000037, Avg loss (per batch) = 0.024763\n","05/21/2020 10:58:44 - INFO - __main__ -   Epoch = 7, Batch = 650, Batch loss = 0.000057, Avg loss (per batch) = 0.025260\n","05/21/2020 10:59:06 - INFO - __main__ -   Epoch = 7, Batch = 700, Batch loss = 0.000101, Avg loss (per batch) = 0.024204\n","05/21/2020 10:59:29 - INFO - __main__ -   Epoch = 7, Batch = 750, Batch loss = 0.000042, Avg loss (per batch) = 0.022801\n","05/21/2020 10:59:51 - INFO - __main__ -   Epoch = 7, Batch = 800, Batch loss = 0.053827, Avg loss (per batch) = 0.025289\n","05/21/2020 11:00:13 - INFO - __main__ -   Epoch = 7, Batch = 850, Batch loss = 0.000127, Avg loss (per batch) = 0.024974\n","05/21/2020 11:00:36 - INFO - __main__ -   Epoch = 7, Batch = 900, Batch loss = 0.000092, Avg loss (per batch) = 0.024957\n","05/21/2020 11:00:58 - INFO - __main__ -   Epoch = 7, Batch = 950, Batch loss = 0.000079, Avg loss (per batch) = 0.027584\n","05/21/2020 11:01:21 - INFO - __main__ -   Epoch = 7, Batch = 1000, Batch loss = 0.000050, Avg loss (per batch) = 0.030415\n","05/21/2020 11:01:43 - INFO - __main__ -   Epoch = 7, Batch = 1050, Batch loss = 0.000307, Avg loss (per batch) = 0.030705\n","05/21/2020 11:02:05 - INFO - __main__ -   Epoch = 7, Batch = 1100, Batch loss = 0.000240, Avg loss (per batch) = 0.029514\n","05/21/2020 11:02:28 - INFO - __main__ -   Epoch = 7, Batch = 1150, Batch loss = 0.000038, Avg loss (per batch) = 0.029611\n","05/21/2020 11:02:50 - INFO - __main__ -   Epoch = 7, Batch = 1200, Batch loss = 0.000125, Avg loss (per batch) = 0.028995\n","05/21/2020 11:03:12 - INFO - __main__ -   Epoch = 7, Batch = 1250, Batch loss = 0.000075, Avg loss (per batch) = 0.028819\n","05/21/2020 11:03:35 - INFO - __main__ -   Epoch = 7, Batch = 1300, Batch loss = 0.225450, Avg loss (per batch) = 0.028352\n","05/21/2020 11:03:57 - INFO - __main__ -   Epoch = 7, Batch = 1350, Batch loss = 0.000080, Avg loss (per batch) = 0.027557\n","05/21/2020 11:04:20 - INFO - __main__ -   Epoch = 7, Batch = 1400, Batch loss = 0.000025, Avg loss (per batch) = 0.027399\n","05/21/2020 11:04:42 - INFO - __main__ -   Epoch = 7, Batch = 1450, Batch loss = 0.000069, Avg loss (per batch) = 0.027546\n","05/21/2020 11:05:04 - INFO - __main__ -   Epoch = 7, Batch = 1500, Batch loss = 0.000024, Avg loss (per batch) = 0.027220\n","05/21/2020 11:05:27 - INFO - __main__ -   Epoch = 7, Batch = 1550, Batch loss = 0.000032, Avg loss (per batch) = 0.027126\n","05/21/2020 11:05:49 - INFO - __main__ -   Epoch = 7, Batch = 1600, Batch loss = 0.000073, Avg loss (per batch) = 0.031513\n","05/21/2020 11:06:11 - INFO - __main__ -   Epoch = 7, Batch = 1650, Batch loss = 0.000115, Avg loss (per batch) = 0.031706\n","05/21/2020 11:06:34 - INFO - __main__ -   Epoch = 7, Batch = 1700, Batch loss = 0.000046, Avg loss (per batch) = 0.032552\n","05/21/2020 11:06:56 - INFO - __main__ -   Epoch = 7, Batch = 1750, Batch loss = 0.000170, Avg loss (per batch) = 0.033498\n","05/21/2020 11:07:19 - INFO - __main__ -   Epoch = 7, Batch = 1800, Batch loss = 0.000027, Avg loss (per batch) = 0.032791\n","05/21/2020 11:07:33 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 11:09:48 - INFO - __main__ -   After 7.000000 epoch, Training loss = 0.033320, Training accuracy = 0.992224\n","05/21/2020 11:10:11 - INFO - __main__ -   Epoch = 8, Batch = 50, Batch loss = 0.000485, Avg loss (per batch) = 0.032120\n","05/21/2020 11:10:33 - INFO - __main__ -   Epoch = 8, Batch = 100, Batch loss = 0.001199, Avg loss (per batch) = 0.016154\n","05/21/2020 11:10:55 - INFO - __main__ -   Epoch = 8, Batch = 150, Batch loss = 0.000074, Avg loss (per batch) = 0.013896\n","05/21/2020 11:11:18 - INFO - __main__ -   Epoch = 8, Batch = 200, Batch loss = 0.000255, Avg loss (per batch) = 0.014916\n","05/21/2020 11:11:40 - INFO - __main__ -   Epoch = 8, Batch = 250, Batch loss = 0.000074, Avg loss (per batch) = 0.015272\n","05/21/2020 11:12:03 - INFO - __main__ -   Epoch = 8, Batch = 300, Batch loss = 0.000028, Avg loss (per batch) = 0.013399\n","05/21/2020 11:12:25 - INFO - __main__ -   Epoch = 8, Batch = 350, Batch loss = 0.000102, Avg loss (per batch) = 0.014315\n","05/21/2020 11:12:47 - INFO - __main__ -   Epoch = 8, Batch = 400, Batch loss = 0.000633, Avg loss (per batch) = 0.014121\n","05/21/2020 11:13:10 - INFO - __main__ -   Epoch = 8, Batch = 450, Batch loss = 0.065276, Avg loss (per batch) = 0.015347\n","05/21/2020 11:13:32 - INFO - __main__ -   Epoch = 8, Batch = 500, Batch loss = 0.000366, Avg loss (per batch) = 0.015308\n","05/21/2020 11:13:54 - INFO - __main__ -   Epoch = 8, Batch = 550, Batch loss = 0.000247, Avg loss (per batch) = 0.015037\n","05/21/2020 11:14:17 - INFO - __main__ -   Epoch = 8, Batch = 600, Batch loss = 0.000032, Avg loss (per batch) = 0.016172\n","05/21/2020 11:14:39 - INFO - __main__ -   Epoch = 8, Batch = 650, Batch loss = 0.000047, Avg loss (per batch) = 0.016767\n","05/21/2020 11:15:02 - INFO - __main__ -   Epoch = 8, Batch = 700, Batch loss = 0.000074, Avg loss (per batch) = 0.015867\n","05/21/2020 11:15:24 - INFO - __main__ -   Epoch = 8, Batch = 750, Batch loss = 0.000033, Avg loss (per batch) = 0.014824\n","05/21/2020 11:15:46 - INFO - __main__ -   Epoch = 8, Batch = 800, Batch loss = 0.035065, Avg loss (per batch) = 0.014502\n","05/21/2020 11:16:09 - INFO - __main__ -   Epoch = 8, Batch = 850, Batch loss = 0.000169, Avg loss (per batch) = 0.015373\n","05/21/2020 11:16:31 - INFO - __main__ -   Epoch = 8, Batch = 900, Batch loss = 0.000077, Avg loss (per batch) = 0.015176\n","05/21/2020 11:16:53 - INFO - __main__ -   Epoch = 8, Batch = 950, Batch loss = 0.000082, Avg loss (per batch) = 0.016114\n","05/21/2020 11:17:16 - INFO - __main__ -   Epoch = 8, Batch = 1000, Batch loss = 0.000039, Avg loss (per batch) = 0.016986\n","05/21/2020 11:17:38 - INFO - __main__ -   Epoch = 8, Batch = 1050, Batch loss = 0.000103, Avg loss (per batch) = 0.018141\n","05/21/2020 11:18:01 - INFO - __main__ -   Epoch = 8, Batch = 1100, Batch loss = 0.000071, Avg loss (per batch) = 0.017325\n","05/21/2020 11:18:23 - INFO - __main__ -   Epoch = 8, Batch = 1150, Batch loss = 0.000031, Avg loss (per batch) = 0.017381\n","05/21/2020 11:18:45 - INFO - __main__ -   Epoch = 8, Batch = 1200, Batch loss = 0.000084, Avg loss (per batch) = 0.017668\n","05/21/2020 11:19:08 - INFO - __main__ -   Epoch = 8, Batch = 1250, Batch loss = 0.000052, Avg loss (per batch) = 0.017145\n","05/21/2020 11:19:30 - INFO - __main__ -   Epoch = 8, Batch = 1300, Batch loss = 0.000132, Avg loss (per batch) = 0.017642\n","05/21/2020 11:19:52 - INFO - __main__ -   Epoch = 8, Batch = 1350, Batch loss = 0.000055, Avg loss (per batch) = 0.016993\n","05/21/2020 11:20:15 - INFO - __main__ -   Epoch = 8, Batch = 1400, Batch loss = 0.000022, Avg loss (per batch) = 0.017647\n","05/21/2020 11:20:37 - INFO - __main__ -   Epoch = 8, Batch = 1450, Batch loss = 0.000043, Avg loss (per batch) = 0.017577\n","05/21/2020 11:21:00 - INFO - __main__ -   Epoch = 8, Batch = 1500, Batch loss = 0.000020, Avg loss (per batch) = 0.017291\n","05/21/2020 11:21:22 - INFO - __main__ -   Epoch = 8, Batch = 1550, Batch loss = 0.000048, Avg loss (per batch) = 0.017206\n","05/21/2020 11:21:44 - INFO - __main__ -   Epoch = 8, Batch = 1600, Batch loss = 0.000051, Avg loss (per batch) = 0.019165\n","05/21/2020 11:22:07 - INFO - __main__ -   Epoch = 8, Batch = 1650, Batch loss = 0.000049, Avg loss (per batch) = 0.019204\n","05/21/2020 11:22:29 - INFO - __main__ -   Epoch = 8, Batch = 1700, Batch loss = 0.000033, Avg loss (per batch) = 0.019506\n","05/21/2020 11:22:52 - INFO - __main__ -   Epoch = 8, Batch = 1750, Batch loss = 0.000071, Avg loss (per batch) = 0.019933\n","05/21/2020 11:23:14 - INFO - __main__ -   Epoch = 8, Batch = 1800, Batch loss = 0.000024, Avg loss (per batch) = 0.019385\n","05/21/2020 11:23:29 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 11:25:44 - INFO - __main__ -   After 8.000000 epoch, Training loss = 0.019048, Training accuracy = 0.995157\n","05/21/2020 11:26:06 - INFO - __main__ -   Epoch = 9, Batch = 50, Batch loss = 0.000735, Avg loss (per batch) = 0.015402\n","05/21/2020 11:26:29 - INFO - __main__ -   Epoch = 9, Batch = 100, Batch loss = 0.000134, Avg loss (per batch) = 0.007843\n","05/21/2020 11:26:51 - INFO - __main__ -   Epoch = 9, Batch = 150, Batch loss = 0.000064, Avg loss (per batch) = 0.005266\n","05/21/2020 11:27:13 - INFO - __main__ -   Epoch = 9, Batch = 200, Batch loss = 0.000089, Avg loss (per batch) = 0.008440\n","05/21/2020 11:27:36 - INFO - __main__ -   Epoch = 9, Batch = 250, Batch loss = 0.000532, Avg loss (per batch) = 0.007877\n","05/21/2020 11:27:58 - INFO - __main__ -   Epoch = 9, Batch = 300, Batch loss = 0.000016, Avg loss (per batch) = 0.006687\n","05/21/2020 11:28:20 - INFO - __main__ -   Epoch = 9, Batch = 350, Batch loss = 0.000060, Avg loss (per batch) = 0.005746\n","05/21/2020 11:28:43 - INFO - __main__ -   Epoch = 9, Batch = 400, Batch loss = 0.000207, Avg loss (per batch) = 0.005836\n","05/21/2020 11:29:05 - INFO - __main__ -   Epoch = 9, Batch = 450, Batch loss = 0.000169, Avg loss (per batch) = 0.006947\n","05/21/2020 11:29:28 - INFO - __main__ -   Epoch = 9, Batch = 500, Batch loss = 0.000130, Avg loss (per batch) = 0.006942\n","05/21/2020 11:29:50 - INFO - __main__ -   Epoch = 9, Batch = 550, Batch loss = 0.000081, Avg loss (per batch) = 0.007408\n","05/21/2020 11:30:12 - INFO - __main__ -   Epoch = 9, Batch = 600, Batch loss = 0.020891, Avg loss (per batch) = 0.006999\n","05/21/2020 11:30:35 - INFO - __main__ -   Epoch = 9, Batch = 650, Batch loss = 0.000031, Avg loss (per batch) = 0.006512\n","05/21/2020 11:30:57 - INFO - __main__ -   Epoch = 9, Batch = 700, Batch loss = 0.000057, Avg loss (per batch) = 0.006236\n","05/21/2020 11:31:19 - INFO - __main__ -   Epoch = 9, Batch = 750, Batch loss = 0.000026, Avg loss (per batch) = 0.006165\n","05/21/2020 11:31:42 - INFO - __main__ -   Epoch = 9, Batch = 800, Batch loss = 0.001631, Avg loss (per batch) = 0.006889\n","05/21/2020 11:32:04 - INFO - __main__ -   Epoch = 9, Batch = 850, Batch loss = 0.000131, Avg loss (per batch) = 0.006488\n","05/21/2020 11:32:27 - INFO - __main__ -   Epoch = 9, Batch = 900, Batch loss = 0.000058, Avg loss (per batch) = 0.006196\n","05/21/2020 11:32:49 - INFO - __main__ -   Epoch = 9, Batch = 950, Batch loss = 0.000035, Avg loss (per batch) = 0.008724\n","05/21/2020 11:33:11 - INFO - __main__ -   Epoch = 9, Batch = 1000, Batch loss = 0.000024, Avg loss (per batch) = 0.010410\n","05/21/2020 11:33:34 - INFO - __main__ -   Epoch = 9, Batch = 1050, Batch loss = 0.000073, Avg loss (per batch) = 0.010699\n","05/21/2020 11:33:56 - INFO - __main__ -   Epoch = 9, Batch = 1100, Batch loss = 0.000049, Avg loss (per batch) = 0.010216\n","05/21/2020 11:34:19 - INFO - __main__ -   Epoch = 9, Batch = 1150, Batch loss = 0.000022, Avg loss (per batch) = 0.010745\n","05/21/2020 11:34:41 - INFO - __main__ -   Epoch = 9, Batch = 1200, Batch loss = 0.000058, Avg loss (per batch) = 0.010329\n","05/21/2020 11:35:03 - INFO - __main__ -   Epoch = 9, Batch = 1250, Batch loss = 0.000040, Avg loss (per batch) = 0.010355\n","05/21/2020 11:35:26 - INFO - __main__ -   Epoch = 9, Batch = 1300, Batch loss = 0.000088, Avg loss (per batch) = 0.010358\n","05/21/2020 11:35:48 - INFO - __main__ -   Epoch = 9, Batch = 1350, Batch loss = 0.000039, Avg loss (per batch) = 0.009977\n","05/21/2020 11:36:11 - INFO - __main__ -   Epoch = 9, Batch = 1400, Batch loss = 0.000016, Avg loss (per batch) = 0.009627\n","05/21/2020 11:36:33 - INFO - __main__ -   Epoch = 9, Batch = 1450, Batch loss = 0.000028, Avg loss (per batch) = 0.009691\n","05/21/2020 11:36:55 - INFO - __main__ -   Epoch = 9, Batch = 1500, Batch loss = 0.000013, Avg loss (per batch) = 0.009646\n","05/21/2020 11:37:18 - INFO - __main__ -   Epoch = 9, Batch = 1550, Batch loss = 0.000016, Avg loss (per batch) = 0.009467\n","05/21/2020 11:37:40 - INFO - __main__ -   Epoch = 9, Batch = 1600, Batch loss = 0.000027, Avg loss (per batch) = 0.010233\n","05/21/2020 11:38:02 - INFO - __main__ -   Epoch = 9, Batch = 1650, Batch loss = 0.000753, Avg loss (per batch) = 0.010876\n","05/21/2020 11:38:25 - INFO - __main__ -   Epoch = 9, Batch = 1700, Batch loss = 0.000023, Avg loss (per batch) = 0.010939\n","05/21/2020 11:38:47 - INFO - __main__ -   Epoch = 9, Batch = 1750, Batch loss = 0.000056, Avg loss (per batch) = 0.010717\n","05/21/2020 11:39:10 - INFO - __main__ -   Epoch = 9, Batch = 1800, Batch loss = 0.000014, Avg loss (per batch) = 0.010427\n","05/21/2020 11:39:24 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 11:41:39 - INFO - __main__ -   After 9.000000 epoch, Training loss = 0.010240, Training accuracy = 0.997271\n","05/21/2020 11:42:02 - INFO - __main__ -   Epoch = 10, Batch = 50, Batch loss = 0.000106, Avg loss (per batch) = 0.010973\n","05/21/2020 11:42:24 - INFO - __main__ -   Epoch = 10, Batch = 100, Batch loss = 0.000073, Avg loss (per batch) = 0.005507\n","05/21/2020 11:42:47 - INFO - __main__ -   Epoch = 10, Batch = 150, Batch loss = 0.000044, Avg loss (per batch) = 0.003683\n","05/21/2020 11:43:09 - INFO - __main__ -   Epoch = 10, Batch = 200, Batch loss = 0.000060, Avg loss (per batch) = 0.004816\n","05/21/2020 11:43:31 - INFO - __main__ -   Epoch = 10, Batch = 250, Batch loss = 0.000051, Avg loss (per batch) = 0.003871\n","05/21/2020 11:43:54 - INFO - __main__ -   Epoch = 10, Batch = 300, Batch loss = 0.000013, Avg loss (per batch) = 0.003253\n","05/21/2020 11:44:16 - INFO - __main__ -   Epoch = 10, Batch = 350, Batch loss = 0.000073, Avg loss (per batch) = 0.009211\n","05/21/2020 11:44:39 - INFO - __main__ -   Epoch = 10, Batch = 400, Batch loss = 0.000053, Avg loss (per batch) = 0.010237\n","05/21/2020 11:45:01 - INFO - __main__ -   Epoch = 10, Batch = 450, Batch loss = 0.000059, Avg loss (per batch) = 0.010251\n","05/21/2020 11:45:23 - INFO - __main__ -   Epoch = 10, Batch = 500, Batch loss = 0.000127, Avg loss (per batch) = 0.009860\n","05/21/2020 11:45:46 - INFO - __main__ -   Epoch = 10, Batch = 550, Batch loss = 0.000043, Avg loss (per batch) = 0.009712\n","05/21/2020 11:46:08 - INFO - __main__ -   Epoch = 10, Batch = 600, Batch loss = 0.000043, Avg loss (per batch) = 0.011355\n","05/21/2020 11:46:30 - INFO - __main__ -   Epoch = 10, Batch = 650, Batch loss = 0.000025, Avg loss (per batch) = 0.010519\n","05/21/2020 11:46:53 - INFO - __main__ -   Epoch = 10, Batch = 700, Batch loss = 0.000044, Avg loss (per batch) = 0.009770\n","05/21/2020 11:47:15 - INFO - __main__ -   Epoch = 10, Batch = 750, Batch loss = 0.000028, Avg loss (per batch) = 0.009485\n","05/21/2020 11:47:38 - INFO - __main__ -   Epoch = 10, Batch = 800, Batch loss = 0.004051, Avg loss (per batch) = 0.009689\n","05/21/2020 11:48:00 - INFO - __main__ -   Epoch = 10, Batch = 850, Batch loss = 0.000052, Avg loss (per batch) = 0.010332\n","05/21/2020 11:48:22 - INFO - __main__ -   Epoch = 10, Batch = 900, Batch loss = 0.000046, Avg loss (per batch) = 0.009910\n","05/21/2020 11:48:45 - INFO - __main__ -   Epoch = 10, Batch = 950, Batch loss = 0.000027, Avg loss (per batch) = 0.010552\n","05/21/2020 11:49:07 - INFO - __main__ -   Epoch = 10, Batch = 1000, Batch loss = 0.000018, Avg loss (per batch) = 0.010941\n","05/21/2020 11:49:29 - INFO - __main__ -   Epoch = 10, Batch = 1050, Batch loss = 0.000082, Avg loss (per batch) = 0.010566\n","05/21/2020 11:49:52 - INFO - __main__ -   Epoch = 10, Batch = 1100, Batch loss = 0.000032, Avg loss (per batch) = 0.010175\n","05/21/2020 11:50:14 - INFO - __main__ -   Epoch = 10, Batch = 1150, Batch loss = 0.000015, Avg loss (per batch) = 0.010206\n","05/21/2020 11:50:36 - INFO - __main__ -   Epoch = 10, Batch = 1200, Batch loss = 0.000033, Avg loss (per batch) = 0.010387\n","05/21/2020 11:50:59 - INFO - __main__ -   Epoch = 10, Batch = 1250, Batch loss = 0.000022, Avg loss (per batch) = 0.010649\n","05/21/2020 11:51:21 - INFO - __main__ -   Epoch = 10, Batch = 1300, Batch loss = 0.000080, Avg loss (per batch) = 0.011319\n","05/21/2020 11:51:44 - INFO - __main__ -   Epoch = 10, Batch = 1350, Batch loss = 0.000023, Avg loss (per batch) = 0.010901\n","05/21/2020 11:52:06 - INFO - __main__ -   Epoch = 10, Batch = 1400, Batch loss = 0.000011, Avg loss (per batch) = 0.010514\n","05/21/2020 11:52:28 - INFO - __main__ -   Epoch = 10, Batch = 1450, Batch loss = 0.000016, Avg loss (per batch) = 0.010178\n","05/21/2020 11:52:51 - INFO - __main__ -   Epoch = 10, Batch = 1500, Batch loss = 0.000014, Avg loss (per batch) = 0.009844\n","05/21/2020 11:53:13 - INFO - __main__ -   Epoch = 10, Batch = 1550, Batch loss = 0.104032, Avg loss (per batch) = 0.010345\n","05/21/2020 11:53:35 - INFO - __main__ -   Epoch = 10, Batch = 1600, Batch loss = 0.000024, Avg loss (per batch) = 0.011430\n","05/21/2020 11:53:58 - INFO - __main__ -   Epoch = 10, Batch = 1650, Batch loss = 0.000019, Avg loss (per batch) = 0.011208\n","05/21/2020 11:54:20 - INFO - __main__ -   Epoch = 10, Batch = 1700, Batch loss = 0.000019, Avg loss (per batch) = 0.011299\n","05/21/2020 11:54:42 - INFO - __main__ -   Epoch = 10, Batch = 1750, Batch loss = 0.000042, Avg loss (per batch) = 0.011088\n","05/21/2020 11:55:05 - INFO - __main__ -   Epoch = 10, Batch = 1800, Batch loss = 0.000012, Avg loss (per batch) = 0.010962\n","05/21/2020 11:55:19 - INFO - __main__ -   Creating a checkpoint.\n","05/21/2020 11:57:34 - INFO - __main__ -   After 10.000000 epoch, Training loss = 0.011227, Training accuracy = 0.997135\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"popKwnL7TwZ5","colab_type":"code","colab":{}},"source":["!python new_model.py --num_train_epochs 10 --max_seq_length 512 --learning_rate 2e-6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4_lMGA9GU3K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"2d870a8e-b1fb-44cb-8f5e-6e51b302d64c","executionInfo":{"status":"ok","timestamp":1590062373170,"user_tz":-330,"elapsed":1559,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["%%writefile evaluation.py\n","import argparse\n","import collections\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","\n","\n","def get_y_true():\n","    \"\"\" \n","    Read file to obtain y_true.\n","    All of five tasks of Sentihood use the test set of task-BERT-pair-NLI-M to get true labels.\n","    All of five tasks of SemEval-2014 use the test set of task-BERT-pair-NLI-M to get true labels.\n","    \"\"\"\n","    true_data_file = \"data/sentihood/bert-pair/test_QA_M.tsv\"\n","\n","    df = pd.read_csv(true_data_file,sep='\\t')\n","    y_true = []\n","    for i in range(len(df)):\n","        label = df['label'][i]\n","        assert label in ['None', 'Positive', 'Negative'], \"error!\"\n","        if label == 'None':\n","            n = 0\n","        elif label == 'Positive':\n","            n = 1\n","        else:\n","            n = 2\n","        y_true.append(n)\n","    \n","    return y_true\n","\n","\n","def get_y_pred(pred_data_dir):\n","    \"\"\" \n","    Read file to obtain y_pred and scores.\n","    \"\"\"\n","    pred=[]\n","    score=[]\n","    with open(pred_data_dir, \"r\", encoding=\"utf-8\") as f:\n","        s=f.readline().strip().split()\n","        while s:\n","            pred.append(int(s[0]))\n","            score.append([float(s[1]),float(s[2]),float(s[3])])\n","            s = f.readline().strip().split()\n","    return pred, score\n","\n","\n","def sentihood_strict_acc(y_true, y_pred):\n","    \"\"\"\n","    Calculate \"strict Acc\" of aspect detection task of Sentihood.\n","    \"\"\"\n","    total_cases=int(len(y_true)/4)\n","    true_cases=0\n","    for i in range(total_cases):\n","        if y_true[i*4]!=y_pred[i*4]:continue\n","        if y_true[i*4+1]!=y_pred[i*4+1]:continue\n","        if y_true[i*4+2]!=y_pred[i*4+2]:continue\n","        if y_true[i*4+3]!=y_pred[i*4+3]:continue\n","        true_cases+=1\n","    aspect_strict_Acc = true_cases/total_cases\n","\n","    return aspect_strict_Acc\n","\n","\n","def sentihood_macro_F1(y_true, y_pred):\n","    \"\"\"\n","    Calculate \"Macro-F1\" of aspect detection task of Sentihood.\n","    \"\"\"\n","    p_all=0\n","    r_all=0\n","    count=0\n","    for i in range(len(y_pred)//4):\n","        a=set()\n","        b=set()\n","        for j in range(4):\n","            if y_pred[i*4+j]!=0:\n","                a.add(j)\n","            if y_true[i*4+j]!=0:\n","                b.add(j)\n","        if len(b)==0:continue\n","        a_b=a.intersection(b)\n","        if len(a_b)>0:\n","            p=len(a_b)/len(a)\n","            r=len(a_b)/len(b)\n","        else:\n","            p=0\n","            r=0\n","        count+=1\n","        p_all+=p\n","        r_all+=r\n","    \n","    Ma_p=p_all/count\n","    Ma_r=r_all/count\n","    aspect_Macro_F1 = 2*Ma_p*Ma_r/(Ma_p+Ma_r)\n","\n","    return aspect_Macro_F1\n","\n","\n","def sentihood_AUC_Acc(y_true, score):\n","    \"\"\"\n","    Calculate \"Macro-AUC\" of both aspect detection and sentiment classification tasks of Sentihood.\n","    Calculate \"Acc\" of sentiment classification task of Sentihood.\n","    \"\"\"\n","    # aspect-Macro-AUC\n","    aspect_y_true=[]\n","    aspect_y_score=[]\n","    aspect_y_trues=[[],[],[],[]]\n","    aspect_y_scores=[[],[],[],[]]\n","    for i in range(len(y_true)):\n","        if y_true[i]>0:\n","            aspect_y_true.append(0)\n","        else:\n","            aspect_y_true.append(1) # \"None\": 1\n","        tmp_score=score[i][0] # probability of \"None\"\n","        aspect_y_score.append(tmp_score)\n","        aspect_y_trues[i%4].append(aspect_y_true[-1])\n","        aspect_y_scores[i%4].append(aspect_y_score[-1])\n","\n","    aspect_auc=[]\n","    for i in range(4):\n","        aspect_auc.append(metrics.roc_auc_score(aspect_y_trues[i], aspect_y_scores[i]))\n","    aspect_Macro_AUC = np.mean(aspect_auc)\n","    \n","    # sentiment-Macro-AUC\n","    sentiment_y_true=[]\n","    sentiment_y_pred=[]\n","    sentiment_y_score=[]\n","    sentiment_y_trues=[[],[],[],[]]\n","    sentiment_y_scores=[[],[],[],[]]\n","    for i in range(len(y_true)):\n","        if y_true[i]>0:\n","            sentiment_y_true.append(y_true[i]-1) # \"Postive\":0, \"Negative\":1\n","            tmp_score=score[i][2]/(score[i][1]+score[i][2])  # probability of \"Negative\"\n","            sentiment_y_score.append(tmp_score)\n","            if tmp_score>0.5:\n","                sentiment_y_pred.append(1) # \"Negative\": 1\n","            else:\n","                sentiment_y_pred.append(0)\n","            sentiment_y_trues[i%4].append(sentiment_y_true[-1])\n","            sentiment_y_scores[i%4].append(sentiment_y_score[-1])\n","\n","    sentiment_auc=[]\n","    for i in range(4):\n","        sentiment_auc.append(metrics.roc_auc_score(sentiment_y_trues[i], sentiment_y_scores[i]))\n","    sentiment_Macro_AUC = np.mean(sentiment_auc)\n","\n","    # sentiment Acc\n","    sentiment_y_true = np.array(sentiment_y_true)\n","    sentiment_y_pred = np.array(sentiment_y_pred)\n","    sentiment_Acc = metrics.accuracy_score(sentiment_y_true,sentiment_y_pred)\n","\n","    return aspect_Macro_AUC, sentiment_Acc, sentiment_Macro_AUC\n","\n","\n","def main():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--pred_data_dir\",  default=None,  type=str, required=True, help=\"The pred data dir.\")\n","    args = parser.parse_args()\n","\n","    result = collections.OrderedDict()\n","    # task_name = \"sentihood_QA_M\"\n","    y_true = get_y_true()\n","    y_pred, score = get_y_pred(args.pred_data_dir)\n","    aspect_strict_Acc = sentihood_strict_acc(y_true, y_pred)\n","    aspect_Macro_F1 = sentihood_macro_F1(y_true, y_pred)\n","    aspect_Macro_AUC, sentiment_Acc, sentiment_Macro_AUC = sentihood_AUC_Acc(y_true, score)\n","    result = {'aspect_strict_Acc': aspect_strict_Acc,\n","            'aspect_Macro_F1': aspect_Macro_F1,\n","            'aspect_Macro_AUC': aspect_Macro_AUC,\n","            'sentiment_Acc': sentiment_Acc,\n","            'sentiment_Macro_AUC': sentiment_Macro_AUC}\n","\n","    for key in result.keys():\n","        print(key, \"=\",str(result[key]))\n","    \n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Overwriting evaluation.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d99JE3RgnEVC","colab_type":"code","outputId":"2be73dc2-f7ba-45a9-f97d-642b5e2a6ad3","executionInfo":{"status":"ok","timestamp":1590062377164,"user_tz":-330,"elapsed":5234,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/bert_test_ep_1.txt"],"execution_count":33,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.4853579175704989\n","aspect_Macro_F1 = 0.014553014553014554\n","aspect_Macro_AUC = 0.9124248305752638\n","sentiment_Acc = 0.8369565217391305\n","sentiment_Macro_AUC = 0.9192682657291691\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MnKbvGsL3xHu","colab_type":"code","outputId":"688fc492-5ca5-4f97-be9e-90c93d30e2ab","executionInfo":{"status":"ok","timestamp":1590062381124,"user_tz":-330,"elapsed":7631,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_1.txt"],"execution_count":34,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.4924078091106291\n","aspect_Macro_F1 = 0.03295300145693847\n","aspect_Macro_AUC = 0.8975338445106795\n","sentiment_Acc = 0.7775919732441472\n","sentiment_Macro_AUC = 0.8926014760388832\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t11UXVpzGnd2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"d60e6290-5d22-4dc2-f888-416e9bbf9bdc","executionInfo":{"status":"ok","timestamp":1590062402094,"user_tz":-330,"elapsed":5681,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["!python evaluation.py --pred_data_dir results/bert_test_ep_2.txt"],"execution_count":35,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.5732104121475055\n","aspect_Macro_F1 = 0.22842444717444718\n","aspect_Macro_AUC = 0.9532764635185316\n","sentiment_Acc = 0.8862876254180602\n","sentiment_Macro_AUC = 0.9359511620345916\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KVk430SrvYh","colab_type":"code","outputId":"f9769588-299d-4f3b-ac9c-8ddd4b053e0d","executionInfo":{"status":"ok","timestamp":1590062405914,"user_tz":-330,"elapsed":8021,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_2.txt"],"execution_count":36,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.6057483731019523\n","aspect_Macro_F1 = 0.3572919662655521\n","aspect_Macro_AUC = 0.9382757947931932\n","sentiment_Acc = 0.8419732441471572\n","sentiment_Macro_AUC = 0.900637268301185\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u6T2w6dIGuUy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"7b0a0831-6fcf-4a0d-ffd5-08706f79c014","executionInfo":{"status":"ok","timestamp":1590062421574,"user_tz":-330,"elapsed":5682,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["!python evaluation.py --pred_data_dir results/bert_test_ep_3.txt"],"execution_count":37,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.6843817787418656\n","aspect_Macro_F1 = 0.5013956247352831\n","aspect_Macro_AUC = 0.9491242471992792\n","sentiment_Acc = 0.8988294314381271\n","sentiment_Macro_AUC = 0.9499355839036572\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gztkkKwEhnm0","colab_type":"code","outputId":"1944799c-013a-4928-95e7-24e200b61488","executionInfo":{"status":"ok","timestamp":1590062424962,"user_tz":-330,"elapsed":8881,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_3.txt"],"execution_count":38,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.6735357917570499\n","aspect_Macro_F1 = 0.5104273480797871\n","aspect_Macro_AUC = 0.9551503716131532\n","sentiment_Acc = 0.8896321070234113\n","sentiment_Macro_AUC = 0.9288381296240735\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4OzmshM8h8Ho","colab_type":"code","outputId":"6ac59a67-bda4-4e85-d87c-af912c7d203e","executionInfo":{"status":"ok","timestamp":1589903201106,"user_tz":-330,"elapsed":18241,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_4.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7049891540130152\n","aspect_Macro_F1 = 0.6066866087911961\n","aspect_Macro_AUC = 0.9581950229955919\n","sentiment_Acc = 0.8653846153846154\n","sentiment_Macro_AUC = 0.9166603273391051\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6P7II_kdiFX9","colab_type":"code","outputId":"181e0c11-e9fa-4359-95dc-763432f0a198","executionInfo":{"status":"ok","timestamp":1589903205882,"user_tz":-330,"elapsed":22475,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_5.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7212581344902386\n","aspect_Macro_F1 = 0.6642281526889388\n","aspect_Macro_AUC = 0.9574389089519515\n","sentiment_Acc = 0.8812709030100334\n","sentiment_Macro_AUC = 0.9298977807498376\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WX2An6SyGyXd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"ee3381c7-61a7-4829-be2d-ce2307682e0d","executionInfo":{"status":"ok","timestamp":1590062435342,"user_tz":-330,"elapsed":4394,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["!python evaluation.py --pred_data_dir results/bert_test_ep_6.txt"],"execution_count":39,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7803687635574837\n","aspect_Macro_F1 = 0.8170441803094864\n","aspect_Macro_AUC = 0.9664392195239979\n","sentiment_Acc = 0.9230769230769231\n","sentiment_Macro_AUC = 0.9620565376948881\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f_Vf0shziKzv","colab_type":"code","outputId":"0a7ecbc2-96b1-4bd8-ab0f-9603e945bec7","executionInfo":{"status":"ok","timestamp":1590062438643,"user_tz":-330,"elapsed":7383,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_6.txt"],"execution_count":40,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7304772234273319\n","aspect_Macro_F1 = 0.7277249556333161\n","aspect_Macro_AUC = 0.9599668719218961\n","sentiment_Acc = 0.8804347826086957\n","sentiment_Macro_AUC = 0.9416683415437377\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-0ZfIQThHLzT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"029b356c-fec4-48b1-ce8b-a6ef4315dc50","executionInfo":{"status":"ok","timestamp":1590062539341,"user_tz":-330,"elapsed":4594,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["!python evaluation.py --pred_data_dir results/bert_test_ep_7.txt"],"execution_count":41,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7933839479392625\n","aspect_Macro_F1 = 0.8111977907749173\n","aspect_Macro_AUC = 0.9668821168630233\n","sentiment_Acc = 0.9180602006688964\n","sentiment_Macro_AUC = 0.9640063875269755\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yib74npgiT01","colab_type":"code","outputId":"6d138aee-88e9-4a37-9b2f-c7e7d8826eb6","executionInfo":{"status":"ok","timestamp":1590062544912,"user_tz":-330,"elapsed":9970,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_7.txt"],"execution_count":42,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7516268980477223\n","aspect_Macro_F1 = 0.7911599523522663\n","aspect_Macro_AUC = 0.9601689048105736\n","sentiment_Acc = 0.8821070234113713\n","sentiment_Macro_AUC = 0.945610721207396\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VUOL_FAMHfmO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"f5df2b87-1e60-4458-ddc5-08d60685b60a","executionInfo":{"status":"ok","timestamp":1590062621272,"user_tz":-330,"elapsed":5635,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}}},"source":["!python evaluation.py --pred_data_dir results/bert_test_ep_8.txt"],"execution_count":43,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.779826464208243\n","aspect_Macro_F1 = 0.8295651398037447\n","aspect_Macro_AUC = 0.9630456170145626\n","sentiment_Acc = 0.9113712374581939\n","sentiment_Macro_AUC = 0.9621131759660732\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pg-yJWk8nWpj","colab_type":"code","outputId":"8d62e7e2-3323-4e0d-c3d2-bf558bd16433","executionInfo":{"status":"ok","timestamp":1590062626214,"user_tz":-330,"elapsed":10121,"user":{"displayName":"Gaurav Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7lL3DXHGteP3tGHVaFfbr4y16RkmYKdkRL74l=s64","userId":"08078359384078211719"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_8.txt"],"execution_count":44,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7613882863340564\n","aspect_Macro_F1 = 0.8229781683810421\n","aspect_Macro_AUC = 0.9609517309616286\n","sentiment_Acc = 0.8904682274247492\n","sentiment_Macro_AUC = 0.9514044347960622\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ibdYKUT-nX2A","colab_type":"code","outputId":"768438d4-56a0-4b9a-e797-52be55c169b6","executionInfo":{"status":"ok","timestamp":1589903246329,"user_tz":-330,"elapsed":5798,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_9.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7581344902386117\n","aspect_Macro_F1 = 0.826013238707906\n","aspect_Macro_AUC = 0.9604645246618003\n","sentiment_Acc = 0.8913043478260869\n","sentiment_Macro_AUC = 0.9511773519008231\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XDZyn5BhngrA","colab_type":"code","outputId":"2049d877-bb8d-431b-f9dc-8607bc231f3f","executionInfo":{"status":"ok","timestamp":1589903257607,"user_tz":-330,"elapsed":6600,"user":{"displayName":"Helping Hand","photoUrl":"","userId":"16705135424764131129"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["!python evaluation.py --pred_data_dir results/test_ep_10.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["aspect_strict_Acc = 0.7592190889370932\n","aspect_Macro_F1 = 0.8144820377205381\n","aspect_Macro_AUC = 0.9594633159328507\n","sentiment_Acc = 0.8879598662207357\n","sentiment_Macro_AUC = 0.9495374822775761\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uCRlqnFjnlMO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}